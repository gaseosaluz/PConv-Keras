{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building the Training Dataset for fqhd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import shutil\n",
    "from tqdm import tqdm, trange, tqdm_notebook\n",
    "from time import sleep"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Count the number of Image files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 69989 .png files\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "dirname = \"/home/edm/work/mldata/images1024x1024/\"\n",
    "os.listdir(dirname)\n",
    "\n",
    "for (dirname, dirs, filenames) in os.walk(dirname):\n",
    "   for filename in filenames:\n",
    "       if filename.endswith('.png') :\n",
    "           count = count + 1\n",
    "print ('There are', count, '.png files')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split the file listing into separate sets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This generates a list of file names. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "filenames.sort()  # make sure that the filenames have a fixed order before shuffling\n",
    "random.seed(230)\n",
    "random.shuffle(filenames) # shuffles the ordering of filenames (deterministic given the chosen seed)\n",
    "\n",
    "split_1 = int(0.8 * len(filenames))\n",
    "split_2 = int(0.9 * len(filenames))\n",
    "\n",
    "\n",
    "train_filenames = filenames[:split_1]\n",
    "val_filenames = filenames[split_1:split_2]\n",
    "test_filenames = filenames[split_2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 55991 files for training\n",
      "There are 6999 files for validation\n",
      "There are 6999 files for testing\n"
     ]
    }
   ],
   "source": [
    "print(\"There are\", len(train_filenames), \"files for training\")\n",
    "print(\"There are\", len(val_filenames), \"files for validation\")\n",
    "print(\"There are\", len(test_filenames), \"files for testing\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up a Progress bar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We should set up a progress bar to get an idea of how long things are taking. Moving this large number of files is very time consuming and while this is being done, the cell will apper to have hung if we don't provide any feedback."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 55991/55991 [00:00<00:00, 2193321.09it/s]\n"
     ]
    }
   ],
   "source": [
    "with tqdm(total=len(train_filenames)) as pbar:\n",
    "    for x in train_filenames:\n",
    "        pbar.update(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save the files to separate directories"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TODO**\n",
    "\n",
    "* The destination directories have to already exist. Maybe at some later time I can add code to check to if they exist and create them dynamically\n",
    "\n",
    "* The copy code below should be refactored into a general purpose function. Right now I am repeating it every time for each directory I need.\n",
    "\n",
    "* The code below is pretty slow. Since I don't expect to do this very often, it may be OK, but it could  benefit from some parellelism. Maybe numba? https://numba.pydata.org/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing 33243.png:   0%|          | 39/55991 [00:00<04:52, 191.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO]: Creating the training dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing 18902.png: 100%|██████████| 55991/55991 [07:01<00:00, 132.88it/s]\n"
     ]
    }
   ],
   "source": [
    "# Copy the train split\n",
    "print (\"[INFO]: Creating the training dataset\")\n",
    "files = train_filenames\n",
    "source  = \"/home/edm/work/mldata/images1024x1024/\"\n",
    "destination = \"/home/edm/work/mldata/fqhd/train/\"\n",
    "\n",
    "with tqdm(total=len(files)) as pbar:\n",
    "    \n",
    "# copy only the .png files. The flicker dataset includes a LICENSE.txt\n",
    "# file and I don't want to include it\n",
    "    \n",
    "    for file in files:\n",
    "        if file.endswith(\".png\"):\n",
    "            src = source + file\n",
    "            dest = destination + file\n",
    "            shutil.copy2(src,destination)\n",
    "        pbar.update(1) \n",
    "        pbar.set_description(\"Processing %s\" % file, refresh = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the test files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing 63377.png:   1%|          | 39/6999 [00:00<00:34, 203.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO]: Creating the test dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing 21215.png: 100%|██████████| 6999/6999 [00:47<00:00, 146.37it/s]\n"
     ]
    }
   ],
   "source": [
    "# Copy the test split\n",
    "tqdm.reset(pbar, total = None)\n",
    "files = test_filenames\n",
    "source  = \"/home/edm/work/mldata/images1024x1024/\"\n",
    "destination = \"/home/edm/work/mldata/fqhd/test/\"\n",
    "\n",
    "print (\"[INFO]: Creating the test dataset\")\n",
    "with tqdm(total=len(files)) as pbar:\n",
    "# copy only the .png files. The flicker dataset includes a LICENSE.txt\n",
    "# file and I don't want to include it\n",
    "\n",
    "    for file in files:\n",
    "        if file.endswith(\".png\"):\n",
    "            src = source + file\n",
    "            dest = destination + file\n",
    "            shutil.copy2(src,destination)\n",
    "        pbar.update(1)\n",
    "        pbar.set_description(\"Processing %s\" % file, refresh = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the val files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing 13441.png:   1%|          | 42/6999 [00:00<00:34, 202.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO]: Creating the validation dataset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing 65834.png: 100%|██████████| 6999/6999 [00:47<00:00, 146.13it/s]\n"
     ]
    }
   ],
   "source": [
    "# Copy the val split\n",
    "tqdm.reset(pbar, total = None)\n",
    "files = val_filenames\n",
    "source  = \"/home/edm/work/mldata/images1024x1024/\"\n",
    "destination = \"/home/edm/work/mldata/fqhd/val/\"\n",
    "\n",
    "print (\"[INFO]: Creating the validation dataset\")\n",
    "with tqdm(total=len(files)) as pbar:\n",
    "# copy only the .png files. The flicker dataset includes a LICENSE.txt\n",
    "# file and I don't want to include it\n",
    "\n",
    "    for file in files:\n",
    "        if file.endswith(\".png\"):\n",
    "            src = source + file\n",
    "            dest = destination + file\n",
    "            shutil.copy2(src,destination)\n",
    "        pbar.update(1)\n",
    "        pbar.set_description(\"Processing %s\" % file, refresh = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
